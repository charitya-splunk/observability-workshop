<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Self-Service Observability on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/index.html</link><description>Recent content in Self-Service Observability on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/index.xml" rel="self" type="application/rss+xml"/><item><title>Background</title><link>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/1-background/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/1-background/index.html</guid><description>Background Let&amp;rsquo;s review a few background concepts on Open Telemetry before jumping into the details.
First we have the Open Telemetry Collector, which lives on hosts or kubernetes nodes. These collectors can collect local information (like cpu, disk, memory, etc.). They can also collect metrics from other sources like prometheus (push or pull) or databases and other middleware.
Source: OTel Documentation
The way the OTel Collector collects and sends data is using pipelines.</description></item><item><title>Collect Data with Standards</title><link>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/2-collect_with_standards/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/2-collect_with_standards/index.html</guid><description>Introduction For this workshop, we&amp;rsquo;ll be doing things that only a central tools or administration would do.
The workshop uses scripts to help with steps that aren&amp;rsquo;t part of the focus of this workshop &amp;ndash; like how to change a kubernetes app, or start an application from a host.
Tip It can be useful to review what the scripts are doing.
So along the way it is advised to run cat &amp;lt;filename&amp;gt; from time to time to see what that step just did.</description></item><item><title>Manage Costs</title><link>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/3-manage_costs/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/3-manage_costs/index.html</guid><description>Introduction Managing Observability costs is a huge challenge. Users can send in data at will, change data, turn on new integrations, and incur costs that are hard to detect before the surprise overage at the end of the month. Exactly the kind of thing thatâ€™s likely to happen to this new team as they set up their new application.
Let&amp;rsquo;s walk through some ways we can mitigate those challenges, while still making the platform easy for teams to send the data they need to.</description></item><item><title>Observability as Code</title><link>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/4-configure_o11yascode/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.51/en/scenarios/self_service_observability/4-configure_o11yascode/index.html</guid><description>Introduction xx</description></item></channel></rss>