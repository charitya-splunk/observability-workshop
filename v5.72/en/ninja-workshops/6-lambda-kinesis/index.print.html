<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=generator content="Relearn 7.1.1"><meta name=description content="This workshop will enable you to build a distributed trace for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Distributed Tracing for AWS Lambda Functions :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="This workshop will enable you to build a distributed trace for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.72/en/ninja-workshops/6-lambda-kinesis/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Distributed Tracing for AWS Lambda Functions :: Splunk Observability Cloud Workshops"><meta property="og:description" content="This workshop will enable you to build a distributed trace for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Distributed Tracing for AWS Lambda Functions :: Splunk Observability Cloud Workshops"><meta itemprop=description content="This workshop will enable you to build a distributed trace for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis"><meta itemprop=dateModified content="2024-10-16T21:58:09-04:00"><meta itemprop=wordCount content="89"><title>Distributed Tracing for AWS Lambda Functions :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v5.72/en/ninja-workshops/6-lambda-kinesis/index.html rel=canonical type=text/html title="Distributed Tracing for AWS Lambda Functions :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v5.72/images/favicon.ico?1730547710 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v5.72/css/fontawesome-all.min.css?1730547710 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.72/css/fontawesome-all.min.css?1730547710 rel=stylesheet></noscript><link href=/observability-workshop/v5.72/css/nucleus.css?1730547710 rel=stylesheet><link href=/observability-workshop/v5.72/css/auto-complete.css?1730547710 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.72/css/auto-complete.css?1730547710 rel=stylesheet></noscript><link href=/observability-workshop/v5.72/css/perfect-scrollbar.min.css?1730547710 rel=stylesheet><link href=/observability-workshop/v5.72/css/fonts.css?1730547710 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.72/css/fonts.css?1730547710 rel=stylesheet></noscript><link href=/observability-workshop/v5.72/css/theme.css?1730547710 rel=stylesheet><link href=/observability-workshop/v5.72/css/theme-splunk-light.css?1730547710 rel=stylesheet id=R-variant-style><link href=/observability-workshop/v5.72/css/chroma-relearn-light.css?1730547710 rel=stylesheet id=R-variant-chroma-style><link href=/observability-workshop/v5.72/css/print.css?1730547710 rel=stylesheet media=print><link href=/observability-workshop/v5.72/css/format-print.css?1730547710 rel=stylesheet><script src=/observability-workshop/v5.72/js/variant.js?1730547710></script><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v5.72",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.variants&&variants.init(["splunk-light","splunk-dark"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA"})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=/observability-workshop/v5.72/en/ninja-workshops/6-lambda-kinesis/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.72/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.72/en/ninja-workshops/index.html><span itemprop=name>Ninja Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lambda Tracing</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.72/en/ninja-workshops/6-lambda-kinesis/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.72/en/ninja-workshops/4-synthetics-scripting/2-api-test/5-view-results/index.html title="View results (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.72/en/ninja-workshops/6-lambda-kinesis/1-setup/index.html title="Setup (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable ninja-workshops" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=distributed-tracing-for-aws-lambda-functions>Distributed Tracing for AWS Lambda Functions</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>45 minutes</span>
</span>&nbsp;
<span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Guy-Francis Kono</span></span><p>This workshop will equip you to build a distributed trace for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis.</p><p>First, we will see how OpenTelemetry&rsquo;s auto-instrumentation captures traces and exports them to your target of choice.</p><p>Then, we will see how we can enable context propagation with manual instrumentation.</p><p>For this workshop Splunk has prepared an Ubuntu Linux instance in AWS/EC2 all pre-configured for you. To get access to that instance, please visit the URL provided by the workshop leader.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 16, 2024</span></span></footer></article><section><h1 class=a11y-only>Subsections of Lambda Tracing</h1><article class=default><header class=headline></header><h1 id=setup>Setup</h1><p><a href=#R-image-36c0f370d1697ffc23ac0e859d8bef79 class=lightbox-link><img alt="Lambda application, not yet instrumented" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/01-Architecture.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-36c0f370d1697ffc23ac0e859d8bef79><img alt="Lambda application, not yet instrumented" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/01-Architecture.png></a></p><h2 id=prerequisites>Prerequisites</h2><h3 id=observability-workshop-instance>Observability Workshop Instance</h3><p>The Observability Workshop is most often completed on a Splunk-issued and preconfigured EC2 instance running Ubuntu.</p><ul><li>Your workshop instructor will have provided you with your credentials to access your instance.</li><li>Alternatively, you can deploy a local observability workshop instance using Multipass.</li></ul><h3 id=aws-command-line-interface-awscli>AWS Command Line Interface (awscli)</h3><p>The AWS Command Line Interface, or <code>awscli</code>, is an API used to interact with AWS resources. In this workshop, it is used by certain scripts to interact with the resource you&rsquo;ll deploy.</p><ul><li><p>Check if the <strong>aws</strong> command is installed on your instance with the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>which aws</span></span></code></pre></div><ul><li><em>The expected output would be <strong>/usr/local/bin/aws</strong></em></li></ul></li><li><p>If the <strong>aws</strong> command is not installed on your instance, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt install awscli</span></span></code></pre></div></li></ul><h3 id=terraform>Terraform</h3><p>Terraform is an Infrastructure as Code (IaC) platform, used to deploy, manage and destroy resource by defining them in configuration files. Terraform employs HCL to define those resources, and supports multiple providers for various platforms and technologies.</p><p>We will be using Terraform at the command line in this workshop to deploy the following resources:</p><ol><li>AWS API Gateway</li><li>Lambda Functions</li><li>Kinesis Stream</li><li>CloudWatch Log Groups</li><li>S3 Bucket<ul><li><em>and other supporting resources</em></li></ul></li></ol><ul><li><p>Check if the <strong>terraform</strong> command is installed on your instance:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>which terraform</span></span></code></pre></div><ul><li><em>The expected output would be <strong>/usr/local/bin/terraform</strong></em></li></ul></li><li><p>If the <strong>terraform</strong> command is not installed on your instance, follow Terraform&rsquo;s recommended installation commands listed below:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget -O- https://apt.releases.hashicorp.com/gpg <span class=p>|</span> sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com </span><span class=k>$(</span>lsb_release -cs<span class=k>)</span><span class=s2> main&#34;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/hashicorp.list
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo apt update <span class=o>&amp;&amp;</span> sudo apt install terraform</span></span></code></pre></div></li></ul><h3 id=workshop-directory-o11y-lambda-workshop>Workshop Directory (o11y-lambda-workshop)</h3><p>The Workshop Directory <code>o11y-lambda-workshop</code> is a repository that contains all the configuration files and scripts to complete both the auto-instrumentation and manual instrumentation of the example Lambda-based application we will be using today.</p><ul><li><p>Confirm you have the workshop directory in your home directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> <span class=o>&amp;&amp;</span> ls</span></span></code></pre></div><ul><li><em>The expected output would include <strong>o11y-lambda-workshop</strong></em></li></ul></li><li><p>If the <strong>o11y-lambda-workshop</strong> directory is not in your home directory, clone it with the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/gkono-splunk/o11y-lambda-workshop.git</span></span></code></pre></div></li></ul><h3 id=aws--terraform-variables>AWS & Terraform Variables</h3><h4 id=aws>AWS</h4><p>The AWS CLI requires that you have credentials to be able to access and manage resources deployed by their services. Both Terraform and the Python scripts in this workshop require these variables to perform their tasks.</p><ul><li><p>Ensure you have the following environment variables set for AWS access:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$AWS_ACCESS_KEY_ID</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$AWS_SECRET_ACCESS_KEY</span></span></span></code></pre></div><ul><li><em>These commands should output text results for your <strong>access key ID</strong> and <strong>secret access key</strong></em></li></ul></li><li><p>If the AWS environment variables aren&rsquo;t set, request those keys from your instructor.</p><ul><li>Replace the <strong>CHANGEME</strong> values for the following variables, then copy and paste them into your command line.</li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>AWS_ACCESS_KEY_ID</span><span class=o>=</span><span class=s2>&#34;CHANGEME&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>AWS_SECRET_ACCESS_KEY</span><span class=o>=</span><span class=s2>&#34;CHANGEME&#34;</span></span></span></code></pre></div></li></ul><h4 id=terraform-1>Terraform</h4><p>Terraform supports the passing of variables to ensure sensitive or dynamic data is not hard-coded in your .tf configuration files.</p><p>Terraform variables are defined by setting TF_VAR_ environment variables and declaring those variables in our TF configuration files.</p><p>In our workshop, Terraform requires variables necessary for deploying the Lambda functions with the right environment variables for the OpenTelemetry Lambda layer, as well as the ingest values for Splunk Observability Cloud.</p><ul><li><p>Ensure you have the following environment variables set for AWS access:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$TF_VAR_o11y_access_token</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$TF_VAR_o11y_realm</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$TF_VAR_otel_lambda_layer</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nv>$TF_VAR_prefix</span></span></span></code></pre></div><ul><li><em>These commands should output text for the <strong>access token</strong>, <strong>realm</strong>, and <strong>otel lambda layer</strong> for Splunk Observability Cloud, which your instructor has, or can, share with you.</em></li><li><em>Also there should be an output for the <strong>prefix</strong> that will be used to name your resources. It will be a value that you provide.</em></li></ul></li><li><p>If the Terraform environment variables aren&rsquo;t set, request the <strong>access token</strong>, <strong>realm</strong>, and <strong>otel lambda layer</strong> from your instructor.</p><ul><li>Replace the <strong>CHANGEME</strong> values for the following variables, then copy and paste them into your command line.</li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>TF_VAR_o11y_access_token</span><span class=o>=</span><span class=s2>&#34;CHANGEME&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>TF_VAR_o11y_realm</span><span class=o>=</span><span class=s2>&#34;CHANGEME&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>TF_VAR_otel_lambda_layer</span><span class=o>=</span><span class=s1>&#39;[&#34;CHANGEME&#34;]&#39;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>TF_VAR_prefix</span><span class=o>=</span><span class=s2>&#34;CHANGEME&#34;</span></span></span></code></pre></div></li></ul><p>Now that we&rsquo;ve squared off the prerequisites, we can get started with the workshop!</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 16, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=auto-instrumentation>Auto-Instrumentation</h1><p>The first part of our workshop will demonstrate how auto-instrumentation with OpenTelemetry allows the OpenTelemetry Collector to auto-detect what language your function is written in, and start capturing traces for those applications.</p><h3 id=the-auto-instrumentation-workshop-directory--contents>The Auto-Instrumentation Workshop Directory & Contents</h3><p>First, let us take a look at the <code>o11y-lambda-workshop/auto</code> directory, and some of its files. This is where all the content for the auto-instrumentation portion of our workshop resides.</p><h4 id=the-auto-directory>The <code>auto</code> Directory</h4><ul><li><p>Run the following command to get into the <code>o11y-lambda-workshop/auto</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/auto</span></span></code></pre></div></li><li><p>Inspect the contents of this directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ls</span></span></code></pre></div><ul><li><p><em>The output should include the following files and directories:</em></p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>get_logs.py    main.tf       send_message.py
</span></span><span class=line><span class=cl>handler        outputs.tf    terraform.tf</span></span></code></pre></div></li></ul></li></ul><h4 id=the-maintf-file>The <code>main.tf</code> file</h4><ul><li><p>Take a closer look at the <code>main.tf</code> file:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat main.tf</span></span></code></pre></div></li></ul><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Questions</div><div class=box-content><ul><li>Can you identify which AWS resources are being created by this template?</li><li>Can you identify where OpenTelemetry instrumentation is being set up?<ul><li><em>Hint: study the lambda function definitions</em></li></ul></li><li>Can you determine which instrumentation information is being provided by the environment variables we set earlier?</li></ul></div></div><p>You should see a section where the environment variables for each lambda function are being set.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>environment <span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=nv>variables</span> <span class=o>=</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>SPLUNK_ACCESS_TOKEN</span> <span class=o>=</span> var.o11y_access_token
</span></span><span class=line><span class=cl>    <span class=nv>SPLUNK_REALM</span> <span class=o>=</span> var.o11y_realm
</span></span><span class=line><span class=cl>    <span class=nv>OTEL_SERVICE_NAME</span> <span class=o>=</span> <span class=s2>&#34;producer-lambda&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>OTEL_RESOURCE_ATTRIBUTES</span> <span class=o>=</span> <span class=s2>&#34;deployment.environment=</span><span class=si>${</span><span class=nv>var</span><span class=p>.prefix</span><span class=si>}</span><span class=s2>-lambda-shop&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>AWS_LAMBDA_EXEC_WRAPPER</span> <span class=o>=</span> <span class=s2>&#34;/opt/nodejs-otel-handler&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>KINESIS_STREAM</span> <span class=o>=</span> aws_kinesis_stream.lambda_streamer.name
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span></span></span></code></pre></div><p>By using these environment variables, we are configuring our auto-instrumentation in a few ways:</p><ul><li><p>We are setting environment variables to inform the OpenTelemetry collector of which Splunk Observability Cloud organization we would like to have our data exported to.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>SPLUNK_ACCESS_TOKEN</span> <span class=o>=</span> var.o11y_access_token
</span></span><span class=line><span class=cl><span class=nv>SPLUNK_ACCESS_TOKEN</span> <span class=o>=</span> var.o11y_realm</span></span></code></pre></div></li><li><p>We are also setting variables that help OpenTelemetry identify our function/service, as well as the environment/application it is a part of.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>OTEL_SERVICE_NAME</span> <span class=o>=</span> <span class=s2>&#34;producer-lambda&#34;</span> <span class=c1># consumer-lambda in the case of the consumer function</span>
</span></span><span class=line><span class=cl><span class=nv>OTEL_RESOURCE_ATTRIBUTES</span> <span class=o>=</span> <span class=s2>&#34;deployment.environment=</span><span class=si>${</span><span class=nv>var</span><span class=p>.prefix</span><span class=si>}</span><span class=s2>-lambda-shop&#34;</span></span></span></code></pre></div></li><li><p>We are setting an environment variable that lets OpenTelemetry know what wrappers it needs to apply to our function&rsquo;s handler so as to capture trace data automatically, based on our code language.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>AWS_LAMBDA_EXEC_WRAPPER - <span class=s2>&#34;/opt/nodejs-otel-handler&#34;</span></span></span></code></pre></div></li><li><p>In the case of the <code>producer-lambda</code> function, we are setting an environment variable to let the function know what Kinesis Stream to put our record to.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>KINESIS_STREAM</span> <span class=o>=</span> aws_kinesis_stream.lambda_streamer.name</span></span></code></pre></div></li><li><p>These values are sourced from the environment variables we set in the Prerequisites section, as well as resources that will be deployed as a part of this Terraform configuration file.</p></li></ul><p>You should also see an argument for setting the Splunk OpenTelemetry Lambda layer on each function</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>layers</span> <span class=o>=</span> var.otel_lambda_layer</span></span></code></pre></div><ul><li><p>The OpenTelemetry Lambda layer is a package that contains the libraries and dependencies necessary to collector, process and export telemetry data for Lambda functions at the moment of invocation.</p></li><li><p>While there is a general OTel Lambda layer that has all the libraries and dependencies for all OpenTelemetry-supported languages, there are also language-specific Lambda layers, to help make your function even more lightweight.</p><ul><li><em>You can see the relevant Splunk OpenTelemetry Lambda layer ARNs (Amazon Resource Name) and latest versions for each AWS region <a href=https://github.com/signalfx/lambda-layer-versions/blob/main/splunk-apm/splunk-apm.md rel=external target=_blank>HERE</a></em></li></ul></li></ul><h4 id=the-producermjs-file>The <code>producer.mjs</code> file</h4><p>Next, let&rsquo;s take a look at the <code>producer-lambda</code> function code:</p><ul><li><p>Run the following command to view the contents of the <code>producer.mjs</code> file:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/o11y-lambda-workshop/auto/handler/producer.mjs</span></span></code></pre></div><ul><li>This NodeJS module contains the code for the producer function.</li><li>Essentially, this function receives a message, and puts that message as a record to the targeted Kinesis Stream</li></ul></li></ul><h3 id=deploying-the-lambda-functions--generating-trace-data>Deploying the Lambda Functions & Generating Trace Data</h3><p>Now that we are familiar with the contents of our <code>auto</code> directory, we can deploy the resources for our workshop, and generate some trace data from our Lambda functions.</p><h4 id=initialize-terraform-in-the-auto-directory>Initialize Terraform in the <code>auto</code> directory</h4><p>In order to deploy the resources defined in the <code>main.tf</code> file, you first need to make sure that Terraform is initialized in the same folder as that file.</p><ul><li><p>Ensure you are in the <code>auto</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/auto</strong></em></li></ul></li><li><p>If you are not in the <code>auto</code> directory, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/auto</span></span></code></pre></div></li><li><p>Run the following command to initialize Terraform in this directory</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform init</span></span></code></pre></div><ul><li><p>This command will create a number of elements in the same folder:</p><ul><li><code>.terraform.lock.hcl</code> file: to record the providers it will use to provide resources</li><li><code>.terraform</code> directory: to store the provider configurations</li></ul></li><li><p>In addition to the above files, when terraform is run using the <code>apply</code> subcommand, the <code>terraform.tfstate</code> file will be created to track the state of your deployed resources.</p></li><li><p>This enables Terraform to manage the creation, state and destruction of resources, as defined within the <code>main.tf</code> file of the <code>auto</code> directory</p></li></ul></li></ul><h4 id=deploy-the-lambda-functions-and-other-aws-resources>Deploy the Lambda functions and other AWS resources</h4><p>Once we&rsquo;ve initialized Terraform in this directory, we can go ahead and deploy our resources.</p><ul><li><p>Run the Terraform command to have the Lambda function and other supporting resources deployed from the <code>main.tf</code> file:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform apply</span></span></code></pre></div><ul><li><p>respond <code>yes</code> when you see the <code>Enter a value:</code> prompt</p></li><li><p>This will result in the following outputs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>Outputs:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>lambda_bucket_name</span> <span class=o>=</span> <span class=s2>&#34;lambda-shop-______-______&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>base_url</span> <span class=o>=</span> <span class=s2>&#34;https://______.amazonaws.com/serverless_stage/producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>producer_function_name</span> <span class=o>=</span> <span class=s2>&#34;______-producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>producer_log_group_arn</span> <span class=o>=</span> <span class=s2>&#34;arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>consumer_function_name</span> <span class=o>=</span> <span class=s2>&#34;_____-consumer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>consumer_log_group_arn</span> <span class=o>=</span> <span class=s2>&#34;arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>environment</span> <span class=o>=</span> <span class=s2>&#34;______-lambda-shop&#34;</span></span></span></code></pre></div></li></ul></li></ul><h4 id=send-some-traffic-to-the-producer-lambda-endpoint-base_url>Send some traffic to the <code>producer-lambda</code> endpoint (<code>base_url</code>)</h4><p>To start getting some traces from our deployed Lambda functions, we would need to generate some traffic. We will send a message to our <code>producer-lambda</code> function&rsquo;s endpoint, which should be put as a record into our Kinesis Stream, and then pulled from the Stream by the <code>consumer-lambda</code> function.</p><ul><li><p>Ensure you are in the <code>auto</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/auto</strong></em></li></ul></li><li><p>If you are not in the <code>auto</code> directory, run the following command</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/auto</span></span></code></pre></div></li></ul><p>The <code>send_message.py</code> script is a Python script that will take input at the command line, add it to a JSON dictionary, and send it to your <code>producer-lambda</code> function&rsquo;s endpoint repeatedly, as part of a while loop.</p><ul><li><p>Run the <code>send_message.py</code> script as a background process</p><ul><li><em>It requires the <code>--name</code> and <code>--superpower</code> arguments</em></li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nohup ./send_message.py --name CHANGEME --superpower CHANGEME <span class=p>&amp;</span></span></span></code></pre></div><ul><li><p>You should see an output similar to the following if your message is successful</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>1<span class=o>]</span> <span class=m>79829</span>
</span></span><span class=line><span class=cl>user@host manual % appending output to nohup.out</span></span></code></pre></div><ul><li><em>The two most import bits of information here are:</em><ul><li><em>The process ID on the first line (<code>79829</code> in the case of my example), and</em></li><li><em>The <code>appending output to nohup.out</code> message</em></li></ul></li><li><em>The <code>nohup</code> command ensures the script will not hang up when sent to the background. It also captures any output from our command in a nohup.out file in the same folder as the one you&rsquo;re currently in.</em></li><li><em>The <code>&</code> tells our shell process to run this process in the background, thus freeing our shell to run other commands.</em></li></ul></li></ul></li><li><p>Next, check the contents of the <code>nohup.out</code> file, to ensure your output confirms your requests to your <code>producer-lambda</code> endpoint are successful:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat nohup.out</span></span></code></pre></div><ul><li>You should see the following output among the lines printed to your screen if your message is successful:</li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;message&#34;</span>: <span class=s2>&#34;Message placed in the Event Stream: hostname-eventStream&#34;</span><span class=o>}</span></span></span></code></pre></div><ul><li>If unsuccessful, you will see:</li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;message&#34;</span>: <span class=s2>&#34;Internal server error&#34;</span><span class=o>}</span></span></span></code></pre></div></li></ul><div class="box notices cstyle important"><div class=box-label><i class="fa-fw fas fa-bolt"></i> Important</div><div class=box-content><p>If this occurs, ask one of the workshop facilitators for assistance.</p></div></div><h4 id=view-the-lambda-function-logs>View the Lambda Function Logs</h4><p>Next, let&rsquo;s take a look at the logs for our Lambda functions.</p><ul><li><p>Run the following script to view your <code>producer-lambda</code> logs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./get_logs.py --function producer</span></span></code></pre></div><ul><li>Hit <code>[CONTROL-C]</code> to stop the live stream after some log events show up</li></ul></li><li><p>Run the following to view your <code>consumer-lambda</code> logs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./get_logs.py --function consumer</span></span></code></pre></div><ul><li>Hit <code>[CONTROL-C]</code> to stop the live stream after some log events show up</li></ul></li></ul><p>Examine the logs carefully.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><ul><li>Do you see OpenTelemetry being loaded? Look out for the lines with <code>splunk-extension-wrapper</code></li></ul></div></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 17, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=splunk-apm-lambda-functions--traces>Splunk APM, Lambda Functions & Traces</h1><p>The Lambda functions should be generating a sizeable amount of trace data, which we would need to take a look at. Through the combination of environment variables and the OpenTelemetry Lambda layer configured in the resource definition for our Lambda functions, we should now be ready to view our functions and traces in Splunk APM.</p><h4 id=view-your-environment-name-in-the-splunk-apm-overview>View your Environment name in the Splunk APM Overview</h4><p>Let&rsquo;s start by making sure that Splunk APM is aware of our <code>Environment</code> from the trace data it is receiving. This is the <code>deployment.name</code> we set as part of the <code>OTEL_RESOURCE_ATTRIBUTES</code> variable we set on our Lambda function definitions in <code>main.tf</code>.</p><p>In Splunk Observability Cloud:</p><ul><li><p>Click on the <code>APM</code> Button from the Main Menu on the left. This will take you to the Splunk APM Overview.</p></li><li><p>Select your APM Environment from the <code>Environment:</code> dropdown.</p><ul><li><em>Your APM environment should be in the <code>PREFIX-lambda-shop</code> format, where the `PREFIX is obtained from the environment variable you set in the Prerequisites section</em></li></ul></li></ul><div class="box notices cstyle note"><div class=box-label><i class="fa-fw fas fa-exclamation-circle"></i> Note</div><div class=box-content><p>It may take a few minutes for your traces to appear in Splunk APM. Try hitting refresh on your browser until you find your environment name in the list of environments.</p></div></div><p><a href=#R-image-5c0fe61b789c744bccf971d7c66ad6af class=lightbox-link><img alt="Splunk APM, Environment Name" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/02-Auto-APM-EnvironmentName.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-5c0fe61b789c744bccf971d7c66ad6af><img alt="Splunk APM, Environment Name" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/02-Auto-APM-EnvironmentName.png></a></p><h4 id=view-your-environments-service-map>View your Environment&rsquo;s Service Map</h4><p>Once you&rsquo;ve selected your Environment name from the Environment drop down, you can take a look at the Service Map for your Lambda functions.</p><ul><li>Click the <code>Service Map</code> Button on the right side of the APM Overview page. This will take you to your Service Map view.</li></ul><p><a href=#R-image-a2a94e04eae0dfb5e1e8908612544745 class=lightbox-link><img alt="Splunk APM, Service Map Button" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/03-Auto-ServiceMapButton.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-a2a94e04eae0dfb5e1e8908612544745><img alt="Splunk APM, Service Map Button" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/03-Auto-ServiceMapButton.png></a></p><p>You should be able to see the <code>producer-lambda</code> function and the call it is making to the Kinesis Stream to put your record.</p><p><a href=#R-image-328cbe01761b293bef661f97faf7af65 class=lightbox-link><img alt="Splunk APM, Service Map" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/04-Auto-ServiceMap.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-328cbe01761b293bef661f97faf7af65><img alt="Splunk APM, Service Map" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/04-Auto-ServiceMap.png></a></p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What about your <code>consumer-lambda</code> function?</p></div></div><h4 id=explore-the-traces-from-your-lambda-functions>Explore the Traces from your Lambda Functions</h4><ul><li>Click the <code>Traces</code> button to view the Trace Analyzer.</li></ul><p><a href=#R-image-b50324d0183f79d838624600b4574f05 class=lightbox-link><img alt="Splunk APM, Trace Button" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/05-Auto-TraceButton.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b50324d0183f79d838624600b4574f05><img alt="Splunk APM, Trace Button" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/05-Auto-TraceButton.png></a></p><p>On this page, we can see the traces that have been ingested from the OpenTelemetry Lambda layer of your <code>producer-lambda</code> function.</p><p><a href=#R-image-27123f737a0fa0de1dad9515f9378859 class=lightbox-link><img alt="Splunk APM, Trace Analyzer" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/06-Auto-TraceAnalyzer.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-27123f737a0fa0de1dad9515f9378859><img alt="Splunk APM, Trace Analyzer" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/06-Auto-TraceAnalyzer.png></a></p><ul><li>Select a trace from the list to examine by clicking on its hyperlinked <code>Trace ID</code>.</li></ul><p><a href=#R-image-78bfd331bafe1ec8c2de972aefcdd202 class=lightbox-link><img alt="Splunk APM, Trace and Spans" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/07-Auto-TraceNSpans.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-78bfd331bafe1ec8c2de972aefcdd202><img alt="Splunk APM, Trace and Spans" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/07-Auto-TraceNSpans.png></a></p><p>We can see that the <code>producer-lambda</code> function is putting a record into the Kinesis Stream. But the action of the <code>consumer-lambda</code> function is missing!</p><p>This is because the trace context is not being propagated. Trace context propagation is not supported out-of-the-box by Kinesis service at the time of this workshop. Our distributed trace stops at the Kinesis service, and we can&rsquo;t see the propagation any further.</p><p>Not yet, at least&mldr;</p><p>Let&rsquo;s see how we work around this in the next section of this workshop. But before that, let&rsquo;s clean up after ourselves!</p><h3 id=clean-up>Clean Up</h3><p>The resources we deployed as part of this auto-instrumenation exercise need to be cleaned. Likewise, the script that was generating traffice against our <code>producer-lambda</code> endpoint needs to be stopped, if it&rsquo;s still running. Follow the below steps to clean up.</p><h4 id=kill-the-send_message>Kill the <code>send_message</code></h4><ul><li><p>If the <code>send_message.py</code> script is still running, stop it with the follwing commands:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>fg</span></span></code></pre></div><ul><li>This brings your background process to the foreground.</li><li>Next you can hit <code>[CONTROL-C]</code> to kill the process.</li></ul></li></ul><h4 id=destroy-all-aws-resources>Destroy all AWS resources</h4><p>Terraform is great at managing the state of our resources individually, and as a deployment. It can even update deployed resources with any changes to their definitions. But to start afresh, we will destroy the resources and redeploy them as part of the manual instrumentation portion of this workshop.</p><p>Please follow these steps to destroy your resources:</p><ul><li><p>Ensure you are in the <code>auto</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/auto</strong></em></li></ul></li><li><p>If you are not in the <code>auto</code> directory, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/auto</span></span></code></pre></div></li><li><p>Destroy the Lambda functions and other AWS resources you deployed earlier:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform destroy</span></span></code></pre></div><ul><li>respond <code>yes</code> when you see the <code>Enter a value:</code> prompt</li><li>This will result in the resources being destroyed, leaving you with a clean environment</li></ul></li></ul><p>This process will leave you with a few files and directories in the <code>auto</code> directory. Do not worry about those.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 17, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=manual-instrumentation>Manual Instrumentation</h1><p>The second part of our workshop will focus on demonstrating how manual instrumentation with OpenTelemetry empowers us to enhance telemetry collection. More specifically, in our case, it will enable us to propagate trace context data from the <code>producer-lambda</code> function to the <code>consumer-lambda</code> function, thus enabling us to see the relationship between the two functions, even across Kinesis Stream, which currently does not support automatic context propagation.</p><h3 id=the-manual-instrumentation-workshop-directory--contents>The Manual Instrumentation Workshop Directory & Contents</h3><p>Once again, we will first start by taking a look at our operating directory, and some of its files. This time, it will be <code>o11y-lambda-workshop/manual</code> directory. This is where all the content for the manual instrumentation portion of our workshop resides.</p><h4 id=the-manual-directory>The <code>manual</code> directory</h4><ul><li><p>Run the following command to get into the <code>o11y-lambda-workshop/manual</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/manual</span></span></code></pre></div></li><li><p>Inspect the contents of this directory with the <code>ls</code> command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ls</span></span></code></pre></div><ul><li><p><em>The output should include the following files and directories:</em></p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>get_logs.py    main.tf       send_message.py
</span></span><span class=line><span class=cl>handler        outputs.tf    terraform.tf</span></span></code></pre></div></li></ul></li></ul><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Do you see any difference between this directory and the auto directory when you first started?</p></div></div><h4 id=compare-auto-and-manual-files>Compare <code>auto</code> and <code>manual</code> files</h4><p>Let&rsquo;s make sure that all these files that LOOK the same, are actually the same.</p><ul><li><p>Compare the <code>main.tf</code> files in the <code>auto</code> and <code>manual</code> directories:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>diff ~/o11y-lambda-workshop/auto/main.tf ~/o11y-lambda-workshop/manual/main.tf</span></span></code></pre></div><ul><li>There is no difference! <em>(Well, there shouldn&rsquo;t be. Ask your workshop facilitator to assist you if there is)</em></li></ul></li><li><p>Now, let&rsquo;s compare the <code>producer.mjs</code> files:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>diff ~/o11y-lambda-workshop/auto/handler/producer.mjs ~/o11y-lambda-workshop/manual/handler/producer.mjs</span></span></code></pre></div><ul><li>There&rsquo;s quite a few differences here!</li></ul></li><li><p>You may wish to view the entire file and examine its content</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/o11y-lambda-workshop/handler/producer.mjs</span></span></code></pre></div><ul><li>Notice how we are now importing some OpenTelemetry objects directly into our function to handle some of the manual instrumentation tasks we require.</li></ul><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=kr>import</span> <span class=p>{</span> <span class=nx>context</span><span class=p>,</span> <span class=nx>propagation</span><span class=p>,</span> <span class=nx>trace</span><span class=p>,</span> <span class=p>}</span> <span class=nx>from</span> <span class=s2>&#34;@opentelemetry/api&#34;</span><span class=p>;</span></span></span></code></pre></div><ul><li>We are importing the following objects from <a href=https://www.npmjs.com/package/@opentelemetry/api rel=external target=_blank>@opentelemetry/api</a> to propagate our context in our producer function:<ul><li>context</li><li>propagation</li><li>trace</li></ul></li></ul></li><li><p>Finally, compare the <code>consumer.mjs</code> files:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>diff ~/o11y-lambda-workshop/auto/handler/consumer.mjs ~/o11y-lambda-workshop/manual/handler/consumer.mjs</span></span></code></pre></div><ul><li><p>Here also, there are a few differences of note. Let&rsquo;s take a closer look</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat handler/consumer.mjs</span></span></code></pre></div><ul><li>In this file, we are importing the following <a href=https://www.npmjs.com/package/@opentelemetry/api rel=external target=_blank>@opentelemetry/api</a> objects:<ul><li>propagation</li><li>trace</li><li>ROOT_CONTEXT</li></ul></li><li>We use these to extract the trace context that was propagated from the producer function</li><li>Then to add new span attributes based on our <code>name</code> and <code>superpower</code> to the extracted trace context</li></ul></li></ul></li></ul><h4 id=propagating-the-trace-context-from-the-producer-function>Propagating the Trace Context from the Producer Function</h4><p>The below code executes the following steps inside the producer function:</p><ol><li>Get the tracer for this trace</li><li>Initialize a context carrier object</li><li>Inject the context of the active span into the carrier object</li><li>Modify the record we are about to pu on our Kinesis stream to include the carrier that will carry the active span&rsquo;s context to the consumer</li></ol><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl><span class=kr>import</span> <span class=p>{</span> <span class=nx>context</span><span class=p>,</span> <span class=nx>propagation</span><span class=p>,</span> <span class=nx>trace</span><span class=p>,</span> <span class=p>}</span> <span class=nx>from</span> <span class=s2>&#34;@opentelemetry/api&#34;</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl><span class=kr>const</span> <span class=nx>tracer</span> <span class=o>=</span> <span class=nx>trace</span><span class=p>.</span><span class=nx>getTracer</span><span class=p>(</span><span class=s1>&#39;lambda-app&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=nx>tracer</span><span class=p>.</span><span class=nx>startActiveSpan</span><span class=p>(</span><span class=s1>&#39;put-record&#39;</span><span class=p>,</span> <span class=kr>async</span><span class=p>(</span><span class=nx>span</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kd>let</span> <span class=nx>carrier</span> <span class=o>=</span> <span class=p>{};</span>
</span></span><span class=line><span class=cl>    <span class=nx>propagation</span><span class=p>.</span><span class=nx>inject</span><span class=p>(</span><span class=nx>context</span><span class=p>.</span><span class=nx>active</span><span class=p>(),</span> <span class=nx>carrier</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kr>const</span> <span class=nx>eventBody</span> <span class=o>=</span> <span class=nx>Buffer</span><span class=p>.</span><span class=nx>from</span><span class=p>(</span><span class=nx>event</span><span class=p>.</span><span class=nx>body</span><span class=p>,</span> <span class=s1>&#39;base64&#39;</span><span class=p>).</span><span class=nx>toString</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=kr>const</span> <span class=nx>data</span> <span class=o>=</span> <span class=s2>&#34;{\&#34;tracecontext\&#34;: &#34;</span> <span class=o>+</span> <span class=nx>JSON</span><span class=p>.</span><span class=nx>stringify</span><span class=p>(</span><span class=nx>carrier</span><span class=p>)</span> <span class=o>+</span> <span class=s2>&#34;, \&#34;record\&#34;: &#34;</span> <span class=o>+</span> <span class=nx>eventBody</span> <span class=o>+</span> <span class=s2>&#34;}&#34;</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nx>console</span><span class=p>.</span><span class=nx>log</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=sb>`Record with Trace Context added:
</span></span></span><span class=line><span class=cl><span class=sb>      </span><span class=si>${</span><span class=nx>data</span><span class=si>}</span><span class=sb>`</span>
</span></span><span class=line><span class=cl>    <span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=kr>await</span> <span class=nx>kinesis</span><span class=p>.</span><span class=nx>send</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=nx>PutRecordCommand</span><span class=p>({</span>
</span></span><span class=line><span class=cl>          <span class=nx>StreamName</span><span class=o>:</span> <span class=nx>streamName</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=nx>PartitionKey</span><span class=o>:</span> <span class=s2>&#34;1234&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=nx>Data</span><span class=o>:</span> <span class=nx>data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}),</span>
</span></span><span class=line><span class=cl>        <span class=nx>message</span> <span class=o>=</span> <span class=sb>`Message placed in the Event Stream: </span><span class=si>${</span><span class=nx>streamName</span><span class=si>}</span><span class=sb>`</span>
</span></span><span class=line><span class=cl>      <span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=nx>span</span><span class=p>.</span><span class=nx>end</span><span class=p>();</span></span></span></code></pre></div><h4 id=extracting-trace-context-in-the-consumer-function>Extracting Trace Context in the Consumer Function</h4><p>The below code executes the following steps inside the consumer function:</p><ol><li>Extract the context that we obtained from <code>producer-lambda</code> into a carrier object.</li><li>Extract the tracer from current context.</li><li>Start a new span with the tracer within the extracted context.</li><li>Bonus: Add extra attributes to your span, including custom ones with the values from your message!</li><li>Once completed, end the span.</li></ol><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=kr>import</span> <span class=p>{</span> <span class=nx>propagation</span><span class=p>,</span> <span class=nx>trace</span><span class=p>,</span> <span class=nx>ROOT_CONTEXT</span> <span class=p>}</span> <span class=nx>from</span> <span class=s2>&#34;@opentelemetry/api&#34;</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl>      <span class=kr>const</span> <span class=nx>carrier</span> <span class=o>=</span> <span class=nx>JSON</span><span class=p>.</span><span class=nx>parse</span><span class=p>(</span> <span class=nx>message</span> <span class=p>).</span><span class=nx>tracecontext</span><span class=p>;</span>
</span></span><span class=line><span class=cl>      <span class=kr>const</span> <span class=nx>parentContext</span> <span class=o>=</span> <span class=nx>propagation</span><span class=p>.</span><span class=nx>extract</span><span class=p>(</span><span class=nx>ROOT_CONTEXT</span><span class=p>,</span> <span class=nx>carrier</span><span class=p>);</span>
</span></span><span class=line><span class=cl>      <span class=kr>const</span> <span class=nx>tracer</span> <span class=o>=</span> <span class=nx>trace</span><span class=p>.</span><span class=nx>getTracer</span><span class=p>(</span><span class=nx>process</span><span class=p>.</span><span class=nx>env</span><span class=p>.</span><span class=nx>OTEL_SERVICE_NAME</span><span class=p>);</span>
</span></span><span class=line><span class=cl>      <span class=kr>const</span> <span class=nx>span</span> <span class=o>=</span> <span class=nx>tracer</span><span class=p>.</span><span class=nx>startSpan</span><span class=p>(</span><span class=s2>&#34;Kinesis.getRecord&#34;</span><span class=p>,</span> <span class=kc>undefined</span><span class=p>,</span> <span class=nx>parentContext</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=nx>span</span><span class=p>.</span><span class=nx>setAttribute</span><span class=p>(</span><span class=s2>&#34;span.kind&#34;</span><span class=p>,</span> <span class=s2>&#34;server&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>      <span class=kr>const</span> <span class=nx>body</span> <span class=o>=</span> <span class=nx>JSON</span><span class=p>.</span><span class=nx>parse</span><span class=p>(</span> <span class=nx>message</span> <span class=p>).</span><span class=nx>record</span><span class=p>;</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=p>(</span><span class=nx>body</span><span class=p>.</span><span class=nx>name</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>span</span><span class=p>.</span><span class=nx>setAttribute</span><span class=p>(</span><span class=s2>&#34;custom.tag.name&#34;</span><span class=p>,</span> <span class=nx>body</span><span class=p>.</span><span class=nx>name</span><span class=p>);</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=p>(</span><span class=nx>body</span><span class=p>.</span><span class=nx>superpower</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>span</span><span class=p>.</span><span class=nx>setAttribute</span><span class=p>(</span><span class=s2>&#34;custom.tag.superpower&#34;</span><span class=p>,</span> <span class=nx>body</span><span class=p>.</span><span class=nx>superpower</span><span class=p>);</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl>      <span class=nx>span</span><span class=p>.</span><span class=nx>end</span><span class=p>();</span></span></span></code></pre></div><p>Now let&rsquo;s see the different this makes!</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 17, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=deploying-lambda-functions--generating-trace-data>Deploying Lambda Functions & Generating Trace Data</h1><p>Now that we know how to apply manual instrumentation to the functions and services we wish to capture trace data for, let&rsquo;s go about deploying our Lambda functions again, and generating traffic against our <code>producer-lambda</code> endpoint.</p><h4 id=initialize-terraform-in-the-manual-directory>Initialize Terraform in the <code>manual</code> directory</h4><p>Seeing as we&rsquo;re in a new directory, we will need to initialize Terraform here once again.</p><ul><li><p>Ensure you are in the <code>manual</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/manual</strong></em></li></ul></li><li><p>If you are not in the <code>manual</code> directory, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/manual</span></span></code></pre></div></li><li><p>Run the following command to initialize Terraform in this directory</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform init</span></span></code></pre></div></li></ul><h4 id=deploy-the-lambda-functions-and-other-aws-resources>Deploy the Lambda functions and other AWS resources</h4><p>Let&rsquo;s go ahead and deploy those resources again as well!</p><ul><li><p>Run the Terraform command to have the Lambda function and other supporting resources deployed from the <code>main.tf</code> file:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform apply</span></span></code></pre></div><ul><li><p>respond <code>yes</code> when you see the <code>Enter a value:</code> prompt</p></li><li><p>This will result in the following outputs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>Outputs:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>lambda_bucket_name</span> <span class=o>=</span> <span class=s2>&#34;lambda-shop-______-______&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>base_url</span> <span class=o>=</span> <span class=s2>&#34;https://______.amazonaws.com/serverless_stage/producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>producer_function_name</span> <span class=o>=</span> <span class=s2>&#34;______-producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>producer_log_group_arn</span> <span class=o>=</span> <span class=s2>&#34;arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>consumer_function_name</span> <span class=o>=</span> <span class=s2>&#34;_____-consumer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>consumer_log_group_arn</span> <span class=o>=</span> <span class=s2>&#34;arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>environment</span> <span class=o>=</span> <span class=s2>&#34;______-lambda-shop&#34;</span></span></span></code></pre></div></li></ul></li></ul><p>As you can tell, aside from the first portion of the base_url, the output should be largely the same as when you ran the auto-instrumentation portion of this workshop</p><h4 id=send-some-traffic-to-the-producer-lambda-endpoint-base_url>Send some traffic to the <code>producer-lambda</code> endpoint (base_url)</h4><p>Once more, we will send our <code>name</code> and <code>superpower</code> as a message to our endpoint. This will then be added to a record in our Kinesis Stream, along with our trace context.</p><ul><li><p>Ensure you are in the <code>manual</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/manual</strong></em></li></ul></li><li><p>If you are not in the <code>manual</code> directory, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/manual</span></span></code></pre></div></li><li><p>Run the <code>send_message.py</code> script as a background process:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nohup ./send_message.py --name CHANGEME --superpower CHANGEME <span class=p>&amp;</span></span></span></code></pre></div></li><li><p>Next, check the contents of the nohup.out file for successful calls to our<code>producer-lambda</code> endpoint:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat nohup.out</span></span></code></pre></div><ul><li><p>You should see the following output among the lines printed to your screen if your message is successful:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;message&#34;</span>: <span class=s2>&#34;Message placed in the Event Stream: hostname-eventStream&#34;</span><span class=o>}</span></span></span></code></pre></div></li><li><p>If unsuccessful, you will see:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;message&#34;</span>: <span class=s2>&#34;Internal server error&#34;</span><span class=o>}</span></span></span></code></pre></div></li></ul></li></ul><div class="box notices cstyle important"><div class=box-label><i class="fa-fw fas fa-bolt"></i> Important</div><div class=box-content><p>If this occurs, ask one of the workshop facilitators for assistance.</p></div></div><h4 id=view-the-lambda-function-logs>View the Lambda Function Logs</h4><p>Let&rsquo;s see what our logs look like now.</p><ul><li><p>Run the following script to view your <code>producer-lambda</code> logs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./get_logs.py --function producer</span></span></code></pre></div><ul><li>Hit <code>[CONTROL-C]</code> to stop the live stream after some log events show up</li></ul></li><li><p>Run the following to view your <code>consumer-lambda</code> logs:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./get_logs.py --function consumer</span></span></code></pre></div><ul><li>Hit <code>[CONTROL-C]</code> to stop the live stream after some log events show up</li></ul></li></ul><p>Examine the logs carefully.</p><h5 id=_workshop-question_><em>Workshop Question</em></h5><blockquote><p>Do you notice the difference?</p></blockquote><h4 id=copy-the-trace-id-from-the-consumer-lambda-logs>Copy the Trace ID from the <code>consumer-lambda</code> logs</h4><p>This time around, we can see that the consumer-lambda log group is logging our message as a <code>record</code> together with the <code>tracecontext</code> that we propagated.</p><p>To copy the Trace ID:</p><ul><li>Take a look at one of the <code>Kinesis Message</code> logs. Within it, there is a <code>data</code> dictionary</li><li>Take a closer look at <code>data</code> to see the nested <code>tracecontext</code> dictionary</li><li>Within the <code>tracecontext</code> dictionary, there is a <code>traceparent</code> key-value pair</li><li>The <code>traceparent</code> key-value pair holds the Trace ID we seek<ul><li>There are 4 groups of values, separated by <code>-</code>. The Trace ID is the 2nd group of characters</li></ul></li><li><strong>Copy the Trace ID, and save it.</strong> We will need it for a later step in this workshop</li></ul><p><a href=#R-image-0e284e466ee1d45d560f8dd6f636353e class=lightbox-link><img alt="Lambda Consumer Logs, Manual Instruamentation" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/08-Manual-ConsumerLogs.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-0e284e466ee1d45d560f8dd6f636353e><img alt="Lambda Consumer Logs, Manual Instruamentation" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/08-Manual-ConsumerLogs.png></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 17, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=splunk-apm-lambda-functions-and-traces-again>Splunk APM, Lambda Functions and Traces, Again!</h1><p>In order to see the result of our context propagation outside of the logs, we&rsquo;ll once again consult the <a href=https://app.us1.signalfx.com/#/apm rel=external target=_blank>Splunk APM UI</a>.</p><h4 id=view-your-lambda-functions-in-the-splunk-apm-service-map>View your Lambda Functions in the Splunk APM Service Map</h4><p>Let&rsquo;s take a look at the Service Map for our environment in APM once again.</p><p>In Splunk Observability Cloud:</p><ul><li><p>Click on the <code>APM</code> Button in the Main Menu.</p></li><li><p>Select your APM Environment from the <code>Environment:</code> dropdown.</p></li><li><p>Click the <code>Service Map</code> Button on the right side of the APM Overview page. This will take you to your Service Map view.</p></li></ul><div class="box notices cstyle note"><div class=box-label><i class="fa-fw fas fa-exclamation-circle"></i> Note</div><div class=box-content><p><em>Reminder: It may take a few minutes for your traces to appear in Splunk APM. Try hitting refresh on your browser until you find your environment name in the list of environments.</em></p></div></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Notice the difference?</p></div></div><ul><li>You should be able to see the <code>producer-lambda</code> and <code>consumer-lambda</code> functions linked by the propagated context this time!</li></ul><p><a href=#R-image-52a45be3e771287d2c1eb951a3999fc0 class=lightbox-link><img alt="Splunk APM, Service Map" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/09-Manual-ServiceMap.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-52a45be3e771287d2c1eb951a3999fc0><img alt="Splunk APM, Service Map" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/09-Manual-ServiceMap.png></a></p><h4 id=explore-a-lambda-trace-by-trace-id>Explore a Lambda Trace by Trace ID</h4><p>Next, we will take another look at a trace related to our Environment.</p><ul><li>Paste the Trace ID you copied from the consumer function&rsquo;s logs into the <code>View Trace ID</code> search box under Traces and click <code>Go</code></li></ul><p><a href=#R-image-82281900cc363474ba9fa1e9ed6d3928 class=lightbox-link><img alt="Splunk APM, Trace Button" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/10-Manual-TraceButton.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-82281900cc363474ba9fa1e9ed6d3928><img alt="Splunk APM, Trace Button" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/10-Manual-TraceButton.png></a></p><div class="box notices cstyle note"><div class=box-label><i class="fa-fw fas fa-exclamation-circle"></i> Note</div><div class=box-content><p>The Trace ID was a part of the trace context that we propagated.</p></div></div><p>You can read up on two of the most common propagation standards:</p><ol><li><a href=https:///www.w3.org/TR/trace-context/#traceparent-header rel=external target=_blank>W3C</a></li><li><a href=https://github.com/openzipkin/b3-propagation#overall-process rel=external target=_blank>B3</a></li></ol><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Which one are we using?</p><ul><li><em>The Splunk Distribution of Opentelemetry JS, which supports our NodeJS functions, <a href=https://docs.splunk.com/observability/en/gdi/get-data-in/application/nodejs/splunk-nodejs-otel-distribution.html#defaults-of-the-splunk-distribution-of-opentelemetry-js rel=external target=_blank>defaults</a> to the <code>W3C</code> standard</em></li></ul></div></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Bonus Question: What happens if we mix and match the W3C and B3 headers?</p></div></div><p><a href=#R-image-46c0adf18eebf66b3a5839576e3afdde class=lightbox-link><img alt="Splunk APM, Trace by ID" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/11-Manual-TraceByID.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-46c0adf18eebf66b3a5839576e3afdde><img alt="Splunk APM, Trace by ID" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/11-Manual-TraceByID.png></a></p><p>Click on the <code>consumer-lambda</code> span.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Can you find the attributes from your message?</p></div></div><p><a href=#R-image-2e86c6134d59742aee5fcaf4bff34659 class=lightbox-link><img alt="Splunk APM, Span Tags" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/12-Manual-SpanTags.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2e86c6134d59742aee5fcaf4bff34659><img alt="Splunk APM, Span Tags" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/12-Manual-SpanTags.png></a></p><h3 id=clean-up>Clean Up</h3><p>We are finally at the end of our workshop. Kindly clean up after yourself!</p><h4 id=kill-the-send_message>Kill the <code>send_message</code></h4><ul><li><p>If the <code>send_message.py</code> script is still running, stop it with the follwing commands:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>fg</span></span></code></pre></div><ul><li>This brings your background process to the foreground.</li><li>Next you can hit <code>[CONTROL-C]</code> to kill the process.</li></ul></li></ul><h4 id=destroy-all-aws-resources>Destroy all AWS resources</h4><p>Terraform is great at managing the state of our resources individually, and as a deployment. It can even update deployed resources with any changes to their definitions. But to start afresh, we will destroy the resources and redeploy them as part of the manual instrumentation portion of this workshop.</p><p>Please follow these steps to destroy your resources:</p><ul><li><p>Ensure you are in the <code>manual</code> directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pwd</span></span></code></pre></div><ul><li><em>The expected output would be <strong>~/o11y-lambda-workshop/manual</strong></em></li></ul></li><li><p>If you are not in the <code>manual</code> directory, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/o11y-lambda-workshop/manual</span></span></code></pre></div></li><li><p>Destroy the Lambda functions and other AWS resources you deployed earlier:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform destroy</span></span></code></pre></div><ul><li>respond <code>yes</code> when you see the <code>Enter a value:</code> prompt</li><li>This will result in the resources being destroyed, leaving you with a clean environment</li></ul></li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 17, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=conclusion>Conclusion</h1><p>Congratulations on finishing the Lambda Tracing Workshop! You have seen how we can complement auto-instrumentation with manual steps to have the <code>producer-lambda</code> function&rsquo;s context be sent to the <code>consumer-lambda</code> function via a record in a Kinesis stream. This allowed us to build the expected Distributed Trace, and to contextualize the relationship between both functions in Splunk APM.</p><p><a href=#R-image-5ab47e567775c54bda5d3bed931df826 class=lightbox-link><img alt="Lambda application, fully instrumented" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/13-Architecture_Instrumented.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-5ab47e567775c54bda5d3bed931df826><img alt="Lambda application, fully instrumented" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/13-Architecture_Instrumented.png></a></p><p>You can now build out a trace manually by linking two different functions together. This comes in handy when your auto-instrumentation, or 3rd-party systems, do not support context propagation out of the box, or when you wish to add custom attributes to a trace for more relevant trace analaysis.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Oct 16, 2024</span></span></footer></article></section></div></main></div><script src=/observability-workshop/v5.72/js/clipboard.min.js?1730547710 defer></script><script src=/observability-workshop/v5.72/js/perfect-scrollbar.min.js?1730547710 defer></script><script src=/observability-workshop/v5.72/js/theme.js?1730547710 defer></script></body></html>