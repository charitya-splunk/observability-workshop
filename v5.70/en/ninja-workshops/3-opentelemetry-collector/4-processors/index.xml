<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/index.html</link><description>Processors are run on data between being received and being exported. Processors are optional though some are recommended. There are a large number of processors included in the OpenTelemetry contrib Collector.
%%{ init:{ "theme":"base", "themeVariables": { "primaryColor": "#ffffff", "clusterBkg": "#eff2fb", "defaultLinkColor": "#333333" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --> M(Receivers) B[JAEGER] --> M(Receivers) C[Prometheus] --> M(Receivers) end subgraph Processors M(Receivers) --> H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --> S(OTLP) H(Filters, Attributes, etc) --> T(JAEGER) H(Filters, Attributes, etc) --> U(Prometheus) end</description><generator>Hugo</generator><language>en</language><atom:link href="https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/index.xml" rel="self" type="application/rss+xml"/><item><title>OpenTelemetry Collector Processors</title><link>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/1-batch-processor/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/1-batch-processor/index.html</guid><description>Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:
send_batch_size (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout. send_batch_size acts as a trigger and does not affect the size of the batch. If you need to enforce batch size limits sent to the next component in the pipeline see send_batch_max_size. timeout (default = 200ms): Time duration after which a batch will be sent regardless of size. If set to zero, send_batch_size is ignored as data will be sent immediately, subject to only send_batch_max_size. send_batch_max_size (default = 0): The upper limit of the batch size. 0 means no upper limit on the batch size. This property ensures that larger batches are split into smaller units. It must be greater than or equal to send_batch_size. For more information on the Batch processor, see the Batch Processor documentation.</description></item><item><title>OpenTelemetry Collector Processors</title><link>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/2-resource-detection/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/2-resource-detection/index.html</guid><description>Resource Detection Processor The resourcedetection processor can be used to detect resource information from the host and append or override the resource value in telemetry data with this information.
By default, the hostname is set to the FQDN if possible, otherwise, the hostname provided by the OS is used as a fallback. This logic can be changed from using using the hostname_sources configuration option. To avoid getting the FQDN and use the hostname provided by the OS, we will set the hostname_sources to os.</description></item><item><title>OpenTelemetry Collector Processors</title><link>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/3-attributes/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.70/en/ninja-workshops/3-opentelemetry-collector/4-processors/3-attributes/index.html</guid><description>Attributes Processor The attributes processor modifies attributes of a span, log, or metric. This processor also supports the ability to filter and match input data to determine if they should be included or excluded for specified actions.
It takes a list of actions that are performed in the order specified in the config. The supported actions are:
insert: Inserts a new attribute in input data where the key does not already exist. update: Updates an attribute in input data where the key does exist. upsert: Performs insert or update. Inserts a new attribute in input data where the key does not already exist and updates an attribute in input data where the key does exist. delete: Deletes an attribute from the input data. hash: Hashes (SHA1) an existing attribute value. extract: Extracts values using a regular expression rule from the input key to target keys specified in the rule. If a target key already exists, it will be overridden. We are going to create an attributes processor to insert a new attribute to all our host metrics called participant.name with a value of your name e.g. marge_simpson.</description></item></channel></rss>