<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Splunk4Rookies - Observability on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/index.html</link><description>Recent content in Splunk4Rookies - Observability on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://splunk.github.io/observability-workshop/v5.6/en/s4r/index.xml" rel="self" type="application/rss+xml"/><item><title>Welcome to the Online Boutique</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/01-online-boutique/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/01-online-boutique/index.html</guid><description>For attendees that are taking the pre-configured workshop, the application will already be deployed for you and your instructor will provide with a link to the Online Boutique application.
For attendees that taking the interactive workshop, you will need to install OpenTelemetry and deploy the application. Hit the **Ninja button below to expand the instructions.
Ninja: Interactive workshop build steps Install the OpenTelemetry Collector using the Splunk Helm chart. First, add the Splunk Helm chart repository to Helm and update.</description></item><item><title>Splunk RUM</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/02-rum/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/02-rum/index.html</guid><description>Splunk Real User Monitoring (RUM) allows your teams to quickly identify and eliminate customer-facing issues across your entire architecture.
Splunk RUM collects performance metrics, web vitals, errors, and other forms of data for every user session to enable you to detect and troubleshoot problems in your application.
In Splunk Observability Cloud click on the RUM tab in the left navigation bar.
As we know, modern web experiences can appear simple, but are complex, asynchronous systems.</description></item><item><title>Splunk APM</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/03-apm/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/03-apm/index.html</guid><description>Hover over the APM link Say This is where the end to end value of the Splunk Observability Cloud starts to show. We can hover over this APM link to reveal some quick, at a glance, info about what’s happening on the backend.
This performance summary is clearly showing two actionable things:
Time is being spent in the app (not db, network, or external); and There are errors occurring in these back-end services, and I can see precisely which service is producing the “root cause” for this particular trace (in this case the payment service in dark red).</description></item><item><title>15. Logs link</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/15-logs-link/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/15-logs-link/index.html</guid><description>Hover over the boxes at the bottom of the trace Say We are federating logs across multiple Splunk instances and indexes, which can be extremely useful when I have logs in multiple places – on-prem or in the cloud.
Let’s navigate to the linked logs.</description></item><item><title>16. Logs</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/16-logs/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/16-logs/index.html</guid><description>Click on the logs that are in Splunk Cloud integration Say I can now see the log entries coming from this specific trace.</description></item><item><title>17. Filtering logs</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/17-filter-logs/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/17-filter-logs/index.html</guid><description>Search for “severity” on the right under the “Fields” section, hover over “error”, and click the = next to “error” Say Log Observer gives me an easy way to aggregate and filter on the logs I need to. Here we are just filtering on the log entries that are errors.</description></item><item><title>18. Error details</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/18-error/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/18-error/index.html</guid><description>Click on one of the errors Say I can see there is a bad token in the deployment of the new version. If we filter by this error message, we see the same issue is causing all of the errors.
We’ve now been successful in narrowing down the offending service, version of code, and specific errors that were causing the problem.
If I were still in the middle of my investigation I can see some additional content that can take me back to the map or trace or into the infrastructure where these errors are found.</description></item><item><title>19. Synthetics</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/19-synthetics/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/19-synthetics/index.html</guid><description>Use the Splunk Observability Suite to check the perfomance of your Website/API Endpoint So far we have have tested the perfomance of our Website by visting and running manual testscenario&amp;rsquo;s to see how our web site perfomed.
But what if we didn&amp;rsquo;t have to wait for that, and could instead test the frontend whenever we want, in both production and pre-production? This is where Synthetics comes in.
As part of this excersise we will clone an exsting Synthetic Test and configure it to test against your website, and have it run automaticly.</description></item><item><title>20. Browser test</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/20-browser-test/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/20-browser-test/index.html</guid><description>Change to your browser tab with the recently failed test run containing long POST checkout request Say Synthetics can test uptime and APIs, but in this example let&amp;rsquo;s look at a browser test, where we are emulating real user behavior of shopping and checking out on the desktop site for my retail application.
We see the details of this test run, what the front end looks like visually, as well as a waterfall of all requests broken down by URL.</description></item><item><title>21. Test failure details</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/21-test-failure/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/21-test-failure/index.html</guid><description>Click the last Transaction or Page tab, scroll through the filmstrip to show the images, and scroll down to the long checkout request Say We see that this test run failed because it never got to confirm the Order ID. Looking at the requests in the checkout, we see a long POST request to checkout with an APM link. Familiar, right?</description></item><item><title>22. APM trace from Synthetics</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/22-apm-link/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/22-apm-link/index.html</guid><description>Click the APM link on the long POST checkout request Say Now if we follow the APM link as we did before in RUM, we see the same issue with an error in the payment service requests, and can follow the same workflow to investigate the issue.
If you would like to continue the investigation, follow the Logs link through Error details steps.</description></item><item><title>23. Workshop Wrap-up</title><link>https://splunk.github.io/observability-workshop/v5.6/en/s4r/23-wrapup/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.6/en/s4r/23-wrapup/index.html</guid><description>Conclusion This wraps up the Splunk for Rookies Workshop of the Splunk Observability Cloud. We were able to:
Understand what real users were experiencing Saw how we can detect these issue though Detectors, Dasboardsand Synthetic Tests Troubleshoot a particularly long page load, by following it’s trace across the front and back end and right to the log entries Use tag spotlight, in both RUM and APM, to understand blast radius and context for our performance issues and errors Today we didn’t even talk about the power of the rest of Splunk Observability Cloud, such as:</description></item></channel></rss>