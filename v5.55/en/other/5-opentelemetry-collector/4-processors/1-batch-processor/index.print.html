<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.125.5"><meta name=generator content="Relearn 6.0.0+tip"><meta name=description content="Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:
send_batch_size (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout."><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:
send_batch_size (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout."><meta property="og:url" content="https://splunk.github.io/observability-workshop/observability-workshop/v5.55/en/other/5-opentelemetry-collector/4-processors/1-batch-processor/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops"><meta property="og:description" content="Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:
send_batch_size (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="Ninja Workshops"><meta property="article:modified_time" content="2023-12-21T14:15:53+00:00"><meta itemprop=name content="OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops"><meta itemprop=description content="Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:
send_batch_size (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout."><meta itemprop=dateModified content="2023-12-21T14:15:53+00:00"><meta itemprop=wordCount content="191"><title>OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/observability-workshop/v5.55/en/other/5-opentelemetry-collector/4-processors/1-batch-processor/index.html rel=canonical type=text/html title="OpenTelemetry Collector Processors :: Splunk Observability Cloud Workshops"><link href=../../../../../images/favicon.ico?1715859593 rel=icon type=image/x-icon sizes=any><link href=../../../../../css/fontawesome-all.min.css?1715859607 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../../css/fontawesome-all.min.css?1715859607 rel=stylesheet></noscript><link href=../../../../../css/nucleus.css?1715859607 rel=stylesheet><link href=../../../../../css/auto-complete.css?1715859607 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../../css/auto-complete.css?1715859607 rel=stylesheet></noscript><link href=../../../../../css/perfect-scrollbar.min.css?1715859607 rel=stylesheet><link href=../../../../../css/fonts.css?1715859607 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../../css/fonts.css?1715859607 rel=stylesheet></noscript><link href=../../../../../css/theme.css?1715859607 rel=stylesheet><link href=../../../../../css/theme-splunk-light.css?1715859607 rel=stylesheet id=R-variant-style><link href=../../../../../css/chroma-relearn-light.css?1715859607 rel=stylesheet id=R-variant-chroma-style><link href=../../../../../css/variant.css?1715859607 rel=stylesheet><link href=../../../../../css/print.css?1715859607 rel=stylesheet media=print><link href=../../../../../css/format-print.css?1715859607 rel=stylesheet><script src=../../../../../js/variant.js?1715859607></script><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../../../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/observability-workshop/v5.55",window.index_js_url="../../../../../en/index.search.js",window.variants&&variants.init(["splunk-light","splunk-dark"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"eu0",rumAccessToken:"TR9BBfgYo7qJfqrfgqjoqA",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"eu0",rumAccessToken:"TR9BBfgYo7qJfqrfgqjoqA"})</script></script><style>:root{--MAIN-WIDTH-MAX:1000rem;--MENU-WIDTH-L:23rem}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=../../../../../en/other/5-opentelemetry-collector/4-processors/1-batch-processor/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../../en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../../en/other/index.html><span itemprop=name>Ninja Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../../en/other/5-opentelemetry-collector/index.html><span itemprop=name>OpenTelemetry Collector</span></a><meta itemprop=position content="3">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../../en/other/5-opentelemetry-collector/4-processors/index.html><span itemprop=name>4. Processors</span></a><meta itemprop=position content="4">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>4.1 Batch</span><meta itemprop=position content="5"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=../../../../../en/other/5-opentelemetry-collector/4-processors/index.html title="OpenTelemetry Collector Processors (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=../../../../../en/other/5-opentelemetry-collector/4-processors/2-resource-detection/index.html title="OpenTelemetry Collector Processors (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable default" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=opentelemetry-collector-processors>OpenTelemetry Collector Processors</h1><h2 id=batch-processor>Batch Processor</h2><p>By default, only the <strong>batch</strong> processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop, we will inherit the following defaults which are hard-coded into the Collector:</p><ul><li><code>send_batch_size</code> (default = 8192): Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout. send_batch_size acts as a trigger and does not affect the size of the batch. If you need to enforce batch size limits sent to the next component in the pipeline see send_batch_max_size.</li><li><code>timeout</code> (default = 200ms): Time duration after which a batch will be sent regardless of size. If set to zero, send_batch_size is ignored as data will be sent immediately, subject to only send_batch_max_size.</li><li><code>send_batch_max_size</code> (default = 0): The upper limit of the batch size. 0 means no upper limit on the batch size. This property ensures that larger batches are split into smaller units. It must be greater than or equal to send_batch_size.</li></ul><p>For more information on the Batch processor, see the <a href=https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md rel=external target=_blank><strong>Batch Processor documentation</strong></a>.</p><footer class=footline><span class="badge cstyle tip badge-with-title"><span class=badge-title class=text-muted>Last Modified By
</span><span class=badge-content>Robert Castley</span>
</span>&nbsp;
<span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted><i class="fa-fw fas fa-calendar"></i>
</span><span class=badge-content>Dec 21, 2023</span></span></footer></article></div></main></div><script src=../../../../../js/clipboard.min.js?1715859607 defer></script><script src=../../../../../js/perfect-scrollbar.min.js?1715859607 defer></script><script src=../../../../../js/theme.js?1715859607 defer></script></body></html>