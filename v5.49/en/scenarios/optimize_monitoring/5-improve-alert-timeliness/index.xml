<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Improve Timeliness of Alerts on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.49/en/scenarios/optimize_monitoring/5-improve-alert-timeliness/index.html</link><description>Recent content in Improve Timeliness of Alerts on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://splunk.github.io/observability-workshop/v5.49/en/scenarios/optimize_monitoring/5-improve-alert-timeliness/index.xml" rel="self" type="application/rss+xml"/><item><title>Create Custom Detector</title><link>https://splunk.github.io/observability-workshop/v5.49/en/scenarios/optimize_monitoring/5-improve-alert-timeliness/1-create-custom-detector/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.49/en/scenarios/optimize_monitoring/5-improve-alert-timeliness/1-create-custom-detector/index.html</guid><description>Splunk Observability Cloud provides detectors, events, alerts, and notifications to keep you informed when certain criteria are met. There are a number of pre-built AutoDetect Detectors that automatically surface when common problem patterns occur, such as when an EC2 instanceâ€™s CPU utilization is expected to reach its limit. Additionally, you can also create custom detectors if you want something more optimized or specific. For example, you want a message sent to a Slack channel or to an email address for the Ops team that manages this Kubernetes cluster when Memory Utilization on their pods has reached 85%.</description></item></channel></rss>