<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Monitoring Horizontal Pod Autoscaling in Kubernetes on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/index.html</link><description>Recent content in Monitoring Horizontal Pod Autoscaling in Kubernetes on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/index.xml" rel="self" type="application/rss+xml"/><item><title>Deploying the OpenTelemetry Collector in Kubernetes using a NameSpace</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/1-deploy-otel/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/1-deploy-otel/index.html</guid><description>1. Kubernetes Navigator 2.0 UI We will be starting this workshop using the new Kubernetes Navigator so please check that you are already using the new Navigator.
When you select Infrastructure from the main menu on the left, followed by selecting Kubernetes, you should see two service panes (K8s nodes and K8s workloads) for Kubernetes, similar to the ones below:
2. Connect to EC2 instance You will be able to connect to the workshop instance by using SSH from your Mac, Linux or Windows device.</description></item><item><title>Tour of the Kubernetes Navigator</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/2-check-new-navigator-short/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/2-check-new-navigator-short/index.html</guid><description>1. Cluster vs Workload View The Kubernetes Navigator offers you two separate use cases to view your Kubernetes data.
The K8s workloads are focusing on providing information in regards to workloads a.k.a. your deployments. The K8s nodes are focusing on providing insight into the performance of clusters, nodes, pods and containers. You will initially select either view depending on your need (you can switch between the view on the fly if required).</description></item><item><title>Deploying PHP/Apache</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/3-deploy-apache/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/3-deploy-apache/index.html</guid><description>1. DNS and Services in Kubernetes The Domain Name System (DNS) is a mechanism for linking various sorts of information with easy-to-remember names, such as IP addresses. Using a DNS system to translate request names into IP addresses makes it easy for end-users to reach their target domain name effortlessly.
Most Kubernetes clusters include an internal DNS service configured by default to offer a lightweight approach for service discovery. Even when Pods and Services are created, deleted, or shifted between nodes, built-in service discovery simplifies applications to identify and communicate with services on the Kubernetes clusters.</description></item><item><title>Fix PHP/Apache Issue</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/4-fix-apache/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/4-fix-apache/index.html</guid><description>1. Kubernetes Resources Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.
You do this by placing a Resource section in the deployment of your application/Pod
Example:
resources: limits: # Maximum amount of CPU &amp;amp; memory for peek use cpu: &amp;#34;8&amp;#34; # Maximum of 8 cores of CPU allowed at for peek use memory: &amp;#34;9Mi&amp;#34; # Maximum allowed 9Mb of memory requests: # Request are the expected amount of CPU &amp;amp; memory for normal use cpu: &amp;#34;6&amp;#34; # Requesting 4 cores of a CPU memory: &amp;#34;4Mi&amp;#34; # Requesting 4Mb of memoryMore information can be found here: Resource Management for Pods and Containers</description></item><item><title>Deploy Load Generator</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/5-deploy-loadgen/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/5-deploy-loadgen/index.html</guid><description>Now let&amp;rsquo;s apply some load against the php-apache pod. To do this, you will need to start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending HTTP GETs to the php-apache service.
1. Review loadgen YAML Inspect the YAML file ~/workshop/k3s/loadgen.yaml and validate the contents using the following command:
cat ~/workshop/k3s/loadgen.yamlThis file contains the configuration for the load generator and will create a new ReplicaSet with two replicas of the load generator image.</description></item><item><title>Setup Horizontal Pod Autoscaling (HPA)</title><link>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/6-setup-hpa/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.32/en/other/hpa/6-setup-hpa/index.html</guid><description>In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), to automatically scale the workload to match demand.
Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.
If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.</description></item></channel></rss>