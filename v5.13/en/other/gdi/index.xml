<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Getting Data In (GDI) with OTel and UF on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/index.html</link><description>Recent content in Getting Data In (GDI) with OTel and UF on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/index.xml" rel="self" type="application/rss+xml"/><item><title>Getting Started with O11y GDI - Real Time Enrichment Workshop</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/1-getting-started/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/1-getting-started/index.html</guid><description>Please note to begin the following lab, you must have completed the prework:
Obtain a Splunk Observability Cloud access key Understand cli commands Follow these steps if using O11y Workshop EC2 instances
1. Verify yelp data files are present ll /var/appdata/yelp*2. Export the following variables export ACCESS_TOKEN=&amp;lt;your-access-token&amp;gt; export REALM=&amp;lt;your-o11y-cloud-realm&amp;gt; export clusterName=&amp;lt;your-k8s-cluster&amp;gt;3. Clone the following repo cd /home/ubuntu git clone https://github.com/leungsteve/realtime_enrichment.git cd realtime_enrichment/workshop python3 -m venv rtapp-workshop source rtapp-workshop/bin/activate</description></item><item><title>Deploy Complex Environments and Capture Metrics</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/2-deploy/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/2-deploy/index.html</guid><description>Objective: Learn how to efficiently deploy complex infrastructure components such as Kafka and MongoDB to demonstrate metrics collection with Splunk O11y IM integrations
Duration: 15 Minutes
Scenario A prospect uses Kafka and MongoDB in their environment. Since there are integrations for these services, youâ€™d like to demonstrate this to the prospect. What is a quick and efficient way to set up a live environment with these services and have metrics collected?</description></item><item><title>Code to Kubernetes - Python</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/3-code-to-kubernetes/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/3-code-to-kubernetes/index.html</guid><description>Code to Kubernetes - Python Objective: Understand activities to instrument a python application and run it on Kubernetes.
Verify the code Containerize the app Deploy the container in Kubernetes Note: these steps do not involve Splunk
Duration: 15 Minutes
1. Verify the code - Review service Navigate to the review directory
cd /home/ubuntu/realtime_enrichment/flask_apps/review/Inspect review.py (realtime_enrichment/flask_apps/review)
cat review.pyfrom flask import Flask, jsonify import random import subprocess review = Flask(__name__) num_reviews = 8635403 num_reviews = 100000 reviews_file = &amp;#39;/var/appdata/yelp_academic_dataset_review.</description></item><item><title>Instrument REVIEWS for Tracing</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/4-instrument/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/4-instrument/index.html</guid><description>1. Use Data Setup to instrument a Python application Within the O11y Cloud UI:
Data Management -&amp;gt; Add Integration -&amp;gt; Monitor Applications -&amp;gt; Python (traces) -&amp;gt; Add Integration
Provide the following to the Configure Integration Wizard:
Service: review
Django: no
collector endpoint: http://localhost:4317
Environment: rtapp-workshop-[YOURNAME]
Kubernetes: yes
Legacy Agent: no
We are instructed to:
Install the instrumentation packages for your Python environment. pip install splunk-opentelemetry[all] splunk-py-trace-bootstrap Configure the Downward API to expose environment variables to Kubernetes resources.</description></item><item><title>Monitor System Logs with Splunk Universal Forwarder</title><link>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/5-forwarder/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v5.13/en/other/gdi/5-forwarder/index.html</guid><description>Objective: Learn how to monitor Linux system logs with the Universal Forwarder sending logs to Splunk Enterprise
Duration: 10 Minutes
Scenario You&amp;rsquo;ve been tasked with monitoring the OS logs of the host running your Kubernetes cluster. We are going to utilize a script that will autodeploy the Splunk Universal Forwarder. You will then configure the Universal Forwarder to send logs to the Splunk Enterprise instance assigned to you.
1. Ensure You&amp;rsquo;re in the Correct Directory we will need to be in /home/ubuntu/session-2 cd /home/ubuntu/session-22.</description></item></channel></rss>